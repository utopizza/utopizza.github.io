<!DOCTYPE html>
<html lang="en">
    <head>
	<meta name="generator" content="Hugo 0.69.2" />
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Utopizza</title>
        <meta name="Description" content="About LoveIt Theme"><meta property="og:title" content="Utopizza" />
<meta property="og:description" content="About LoveIt Theme" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://utopizza.github.io/" />
<meta property="og:image" content="https://utopizza.github.io/logo.png"/>
<meta property="og:updated_time" content="2020-08-04T00:00:00+00:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://utopizza.github.io/logo.png"/>

<meta name="twitter:title" content="Utopizza"/>
<meta name="twitter:description" content="About LoveIt Theme"/>
<meta name="application-name" content="Utopizza">
<meta name="apple-mobile-web-app-title" content="Utopizza"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://utopizza.github.io/" /><link rel="alternate" href="/index.xml" type="application/rss+xml" title="Utopizza">
    <link rel="feed" href="/index.xml" type="application/rss+xml" title="Utopizza"><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "WebSite",
        "url": "https:\/\/utopizza.github.io\/","inLanguage": "en","author": {
                "@type": "Person",
                "name": "yusheng"
            },"description": "About LoveIt Theme","image": "https:\/\/utopizza.github.io\/cover.png","thumbnailUrl": "https:\/\/utopizza.github.io\/logo.png","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","name": "Utopizza"
    }
    </script></head>
    <body><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Utopizza"><span class="header-title-pre"><i class='far fa-kiss-wink-heart fa-fw'></i></span>Utopizza</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/categories/"> Categories </a><a class="menu-item" href="https://github.com/utopizza" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i>  </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Utopizza"><span class="header-title-pre"><i class='far fa-kiss-wink-heart fa-fw'></i></span>Utopizza</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/categories/" title="">Categories</a><a class="menu-item" href="https://github.com/utopizza" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="page home"><div class="home-profile"><div class="home-avatar"><a href="/posts/" title="Posts"><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="/avatar.jpg"
        data-srcset="/avatar.jpg, /avatar.jpg 1.5x, /avatar.jpg 2x"
        data-sizes="auto"
        alt="Posts"
        title="Posts" /></a></div><h1 class="home-title">CODE FOR FOOD :)</h1><h2 class="home-subtitle"><div id="id-1" class="typeit"></div></h2><div class="social-links"><a href="https://github.com/utopizza" title="GitHub" target="_blank" rel="noopener noreffer me"><i class="fab fa-github-alt fa-fw"></i></a><a href="mailto:648847079@qq.com" title="Email" rel=" me"><i class="far fa-envelope fa-fw"></i></a></div></div>
<article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/2020-08-04-%E8%AE%BA%E6%96%87-kafka/">Kafka</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>yusheng</a></span>&nbsp;<span class="post-publish">
            published on&nbsp;<time datetime=2020-08-04>2020-08-04</time>
        </span>&nbsp;
            <span class="post-category">included in<a href="/categories/thesis/">
                        <i class="far fa-folder fa-fw"></i>Thesis
                    </a></span></div><div class="content">一、背景问题
在互联网公司中往往会产生大量的日志数据（log data），例如（1）用户事件如用户的登录、网页访问、点击、收藏、分享、评论、搜索；（2）内部系统产生的事件例如服务调用、错误日志、网络事件、系统调用等等。这些日志数据十分重要，可用于分析用户喜好、系统使用情况等等。以往这些日志数据一般用于离线的数据分析，然而随着互联网业务蓬勃的发展，越来越需要更加实时地利用这些日志数据来进行在线分析，例如（1）根据用户搜索历史进行实时更新的个性化推荐、相关推荐、广告投放（2）系统实时识别垃圾邮件、非法数据并自动进行过滤等等。因此，一些早期的系统，例如Facebook的Scribe，Yahoo的Data Highway，Cloudera的Flume等等，都是被设计成把日志数据进行收集并写入Hadoop这样的数据仓库然后进行离线的分析，不能满足进行实时大规模日志在线分析的需求。业界需要一个能支持延迟秒级的实时（real-time）日志收集系统。
二、Kafka
1、基本概念&amp;架构
 一个message流被称为一个topic，每个topic下有多个partition分区（分区数量十分重要，因为它决定了可以并行消费的并行度，见下文） 存储message的kafka节点称为broker。Kafka是一个分布式系统，有多个broker节点，每个broker节点存储一个或者多个partition分区 每个producer可以推送message到一个topic 每个consumer可以订阅一个或者多个topic，从对应的broker中拉取message  2、Efficiency
（1）简单的存储结构
每个topic的每个partition分区对应一个逻辑日志，该日志物理上其实是由一系列的文件片（segment file）构成，每个文件片大约1GB。每当producer推送一个message到某个partition时，broker只是简单地把该message追加到最后一个片文件的末尾。考虑到写磁盘的性能问题，kafka只有在指定数量的message到达、或者指定时间周期结束才执行一次flush把文件片写入磁盘。
至于message的数据结构，与传统message系统不同，kafka中的message并没有所谓的“messageId”，每个message只根据它在日志中的offset来定位：下一条message在日志中的位置等于当前message的位置+message的长度。
consumer从一个partition消费message时，它只能从某个offset开始连续地消费，并且该offset之前的message已经完成消费。consumer在向broker提交每个的pull请求中都会带上所请求的message的offset以及请求的字节数。broker根据offset找到对应的文件片（会在内存中维护一个“文件片首部offset”与“文件片”的映射关系），定位message，然后发送被请求的数据返回给consumer。consumer收到数据后，计算出下一个message的offset然后再继续发送请求。
（2）高效的传输方式
producer可以在单个send请求中一次性提交多个message；同样，consumer也可以在单个pull请求中一次性拉取多个message。
另外，kafka为了防止数据在机器上被缓冲两次（double buffering），它不在内存中缓存任何数据，所有数据只利用了操作系统的页缓冲（page cache，应该就是操作系统底层为写磁盘提供的内核缓冲区）。这样做的好处，文中解析是基本不用考虑内存的垃圾回收，并且在kafka进程重启的时候可以很方便的从页缓冲中重新加载数据（如果是维护在内存中，进程吃消失后分配的内存会被回收释放）
更进一步，kafka对网络传输也做了优化。传统的程序把文件数据发送到网络中一般需要以下几个步骤：
 从磁盘或者其他存储媒体把文件数据读到操作系统内核的缓冲区（page cache） 从内核缓冲区把数据拷贝到应用程序中的buffer 把数据从应用程序中的buffer又重新拷贝到内核中的另一个缓冲区（可能是为网卡分配的缓冲） 把内核缓冲区中的数据发送到socket套接字层，进行网络传输  可见上述过程经历了4次拷贝：文件-》内核缓冲-》应用程序缓冲-》内核缓冲-》socket。然而在Linux或者Unix类的操作系统中，其实有一个名为“sendfile”的API可以直接把文件读到一个内核缓冲后直接发送到socket，kafka利用了该API进行高效的文件数据发送：文件-》内核缓冲-》socket。
（3）无状态broker
在kafka中，每个consumer消费到哪个offset位置并不会被kafka记录，而是由consumer自己进行记录。这样设计的好处是极大了简化了kafka系统的复杂度。但是这样会引入另一个问题：kafka无法知道一个message是否已经被所有的consumer消费过，是否可以进行删除。kafka使用了一个简单解决方案——每个message保留7天，超过该时间的message会被删除。这样设计的好处一是简洁，二是有一定的容灾能力，例如consumer崩溃或者出现一些故障后，可以减小offset从头消费，重新获取消费错误或丢失的数据。
3、分布式协作
在kafka中，可以定义一个consumer组（consumer group），每个这样的组消费一个指定的topic，该topic下的每个partition只能被组中的一个consumer消费，该consumer可以是一个线程或者进程。这样设计的好处是足够简单，因为如果有多个consumer同时消费一个partition，势必需要进行同步来保证message不会被一个组重复消费，可能需要引入锁，这样会使得消费效率大打折扣。因为规定了组内一个consumer只能消费一个partition，因此组内的consumer同步只会出现在进行rebalance的时候，而这是一个出现频率很低的场景。
对于kafka节点结构，它并没有设计成master-slave结构，而是每个broker均为同等地位的数据节点，但是会把一些重要的集群信息存放到Zookeeper中。Zookeeper在kafka中负责的任务主要有：
 监测broker、consumer的加入和离开 触发一次rebalance，当上一点发生的时候 记录consumer与partition对应关系，追踪每个partition的offset  4、交付保证
kafka只保证“至少一次”的数据交付（at-least-once）。如果外部应用程序不能引入重复数据，则它需要自行实现去重逻辑（deduplicated logic）。kafka只保证单个partition内的message会被按顺序交付给consumer，并不会保证不同partition之间的message的交付顺序。</div><div class="post-footer">
        <a href="/2020-08-04-%E8%AE%BA%E6%96%87-kafka/">Read More</a></div>
</article>
<article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/2020-07-26-%E8%AE%BA%E6%96%87-raft/">Raft</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>yusheng</a></span>&nbsp;<span class="post-publish">
            published on&nbsp;<time datetime=2020-07-26>2020-07-26</time>
        </span>&nbsp;
            <span class="post-category">included in<a href="/categories/thesis/">
                        <i class="far fa-folder fa-fw"></i>Thesis
                    </a></span></div><div class="content">一、背景及问题
共识算法（consensus algorithm）在实现大型分布式系统的可靠性方面扮演了十分关键的角色，因为它允许集群在部分机器故障的情况下保持任务正常运行。在过去十年中，主流的共识算法叫Paxos，大部分系统都使用了这个算法，并且该算法一度成为标准的教材。然而，该算法有一个缺陷就是过于复杂，想要完全理解或者完美实现都十分困难。因此，斯坦福的Diego Ongaro和John Ousterhout便提出了一个相对容易理解、容易实现的共识算法，命名为Raft。
二、相关概念
Replicated state machine：复制状态机，是共识算法的起源之处。像GFS、HDFS等的大规模分布式系统，其leader节点都只有一个，存在单点故障问题。要保证集群即使出现该故障的情况下自动恢复正常运行，如集群配置信息、leader选举心跳信息等数据必须克服单点故障的问题，这就要求这些重要的数据有可靠的方式来进行备份。一种可靠的方式就是使用复制状态机，如下图所示，复制状态机一般是通过复制日志（replicated log）来实现。每个机器上都会维护一份复制日志，日志的内容是一系列的command，机器会按日志的顺序来执行这些command，来修改自己的状态。只要保证每个机器上的复制日志是完全一致，那么就可以保证每个机器的操作结果是一致的。其中，共识算法的主要作用就是通过一些通信手段，来保持集群中每个机器的复制日志完全一致。目前比较有名的复制状态机的实现是Zookeeper和Chubby。
三、Raft算法
总的来说，Raft首先会从集群中选举一个leader，整个集群的复制日志完全由leader来维护：leader节点接收client端发送过来的日志实体（log entry），然后把日志实体分发给集群中其他节点，并告诉其他节点什么时候可以安全地执行这些日志，从而修改他们的状态。当leader宕机故障时，集群会自动发起选举，选出一个新的leader继续保持集群运行。为了便于理解和实践，Raft把共识问题拆分成三个彼此独立的子问题，从而逐一解决：（1）leader选举（2）日志复制（3）安全
1、Raft基础
Raft集群（一般规模为5台机器）中的节点在任何时刻（可以运行的情况下）必为以下三种状态之一：（1）leader（2）follower（3）candidate。在正常情况下，集群中只有一个leader，其余均为follower。follower不响应任何client端请求，它只会把这些请求重定向给leader，并且只响应leader的请求。
Raft把时间分割成任意长度的周期（term），这些周期用连续的整数来唯一地标识，可以理解为周期id。每个周期都由leader选举开始，在这个周期内如果一个节点当选为leader，它会一直作为leader直到这个周期结束。集群中每个节点自身都会维护一个周期id作为自己看到的当前周期。当节点之间进行通信时会带上自己的当前周期，如果节点发现对方周期id比自己大，则更新自己的当前周期；如果节点发现自己的当前周期已经过期，则马上把自己转为follower状态；如果节点发现对方的周期已经过期，则直接拒绝对方的请求。
2、leader选举
Raft使用心跳机制（heartbeat）来触发leader选举。当Raft集群刚启动时，所有节点都是follower状态。follower节点一段时间内发现没有收到来自leader的心跳，认为leader节点已经失效（election timeout），则马上把自己转变为candidate状态，并将自己的当前周期增大。它会先为自己投票，然后向集群中其他节点发起拉票请求（RequestVote RPC）。candidate节点会一直持续这个状态直到（1）它获得多数票从而赢得选举成为新leader（2）其他节点胜出成为新leader（3）选举超时，没有选出新leader。
Raft投票规则：（1）每个节点每次选举周期内最多投出一票（2）先到先得原则，给先请求的节点投票（2）candidate只给自己投一票，然后并发地向其他节点拉票（4）特殊情况下，可能会进入僵持状态——例如所有节点同时进入candidate状态，只给自己投票，然后等等其他人给自己投票，此时的集群状态称为“split”。该论文解决这个问题使用了一种简单的方法，就是随机话选举超时时间，避免多个节点同时开启选举周期，使得先开启选举的节点有先发优势成为新leader，减少集群不可用时间。
当一个candidate成为新leader后，马上开始向其他节点发送心跳宣告自己的leader身份。其他节点确认该新leader的当前周期是有效周期后，认可新leader的身份，把自己转变为follower；否则无视该leader，继续保持选举。
3、日志复制
当节点成为leader后，开始负责响应client的请求。client的请求会包含一个需要整个集群都执行的command。leader首先会把该command追加到自己的日志中，然后通过RPC（AppendEntries RPCs）把日志分发到其他节点。若某个follower宕机或者网络丢包没有复制成功，leader会无限地重新尝试，直到复制成功。分发完成后，leader执行该command，修改自己的状态，然后把执行结果返回给client。具体关于日志的组织形式、压缩方法，详见原论文。
4、安全性
这部分较为繁琐，详见原论文。</div><div class="post-footer">
        <a href="/2020-07-26-%E8%AE%BA%E6%96%87-raft/">Read More</a></div>
</article>
<article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/2019-05-19-%E7%AE%97%E6%B3%95-pagerank%E5%9C%A8spark%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E7%8E%B0/">PageRank在Spark的分布式实现</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>yusheng</a></span>&nbsp;<span class="post-publish">
            published on&nbsp;<time datetime=2019-05-19>2019-05-19</time>
        </span>&nbsp;
            <span class="post-category">included in<a href="/categories/algorithm/">
                        <i class="far fa-folder fa-fw"></i>Algorithm
                    </a></span></div><div class="content">最近在研究 MapReduce 和 Spark 的相关资料，顺便补个关于如何在虚拟机中搭建的 Spark 上分布式运行 PageRank 算法的博客。犹记得这个小任务是研一开学时，导师布置的第一个小任务，而现在马上就要硕士毕业答辩了，不禁思绪万千。
一、PageRank 算法
PageRank 算法是谷歌的起家算法，凭借该算法谷歌击败了当时所有的其他门户网站以及搜索引擎。该算法的目的是对数以亿计的网页进行排序，重要的网页将被排在前列，作为搜索结果返回给用户。想起了昆丁的电影《低俗小说》中的对白：“如果你要把一具尸体藏起来，你知道世界上哪里最安全吗？那就是谷歌搜索结果的第二页”。言外之意，谷歌搜索的前几条解决方案总能满足用户，用户永远不需要翻到第二页寻找答案。由此可见谷歌的搜索算法及 PageRank 网页排序算法之强大。
PageRank 算法的详细介绍见 维基百科。总而言之，该算法的主要思路是：如果一个网页被很多重要的网页指向，那么它也是一个重要的网页。具体地，互联网中的每个网页被抽象成一个节点；如果网页 A 包含网页 B 的链接，那么有一条有向边从节点 A 指向节点 B。如此，互联网中的网页及其链接被抽象成一个由节点及有向边组成的巨大拓扑图。
拓扑图建立好后，初始化系统，令每个节点的重要性分数均为1。然后开始迭代系统，在每一轮迭代中，对于每个节点，做如下两件事：
 如果出边是加权的，将该节点的分数按权重比例进行拆解并传送到对应的节点；如果出边不加权，那么将该节点的分数平均拆解并传送 搜集从其他节点传送过来的分数并求和，替换该节点原来的分数  该过程从数学上来说就是一个 马尔可夫过程，可以从数学上证明其收敛性。也就是说，该系统经过若干次迭代，必定可以演化到一个平衡态。在这个状态下，每个节点的每一次分数收入约等于其分数支出。此时，每个节点上的分数就是稳定的分数，PageRank 算法按照该分数从大到小对网页进行排序并（分页地）返回给用户。
二、PageRank 算法的 Spark 分布式实现
输入数据是一个文件，如下所示。第一行只有一个数字，表明了该数据集一共有 114529 个网页节点。从第二行开始，每一行表示一个节点的出边以及对应的权重，以 [key-value] 形式表示 ：[指向的节点id:权重]。在使用该数据集时，需要把第一行的数字删去，刚好剩下一共 114529 行，每一行的行号表示其节点id。例如，删掉第一行后，第 2 行为空行，说明节点 2 出度为 0，不指向任何其他节点；第 3 行的数据表示节点 3 指向了节点 8107、节点 22950 和 节点 108053，边的权重分别为 3320、4 和 1。
要分布式实现 PageRank，就需要按 MapReduce 编程范式来编写代码。MapReduce 接受的输入是 key-value 对，在 Map 过程中映射成新的 key-value 对，在 Reduce 过程中对相同 key 的 values 进行聚合，输入最终结果。为方便起见，使用函数式编程语言 Scala 编写。伪码如下：</div><div class="post-footer">
        <a href="/2019-05-19-%E7%AE%97%E6%B3%95-pagerank%E5%9C%A8spark%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E7%8E%B0/">Read More</a></div>
</article>
<article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/2019-05-09-%E8%AE%BA%E6%96%87-spark/">Spark</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>yusheng</a></span>&nbsp;<span class="post-publish">
            published on&nbsp;<time datetime=2019-05-09>2019-05-09</time>
        </span>&nbsp;
            <span class="post-category">included in<a href="/categories/thesis/">
                        <i class="far fa-folder fa-fw"></i>Thesis
                    </a></span></div><div class="content">一、背景及问题
在谷歌提出了 MapReduce 编程模型之后，UC Berkeley 在此基础上提出了一个更加高效的模型，称为 Spark。其核心思想是将 MapReduce 的中间结果缓存到内存中，使得 Workers 可以快速读取数据而无需启动延迟极大的磁盘读取操作。这种编程模型针对一些迭代次数高、需要反复使用或者修改数据的计算任务尤其有效。根据论文的实验，Spark 在一些高迭代次数的算法实验中处理速度是 MapReduce 的 10 倍以上。
然而因为没有了将中间结果写磁盘的操作来保证容灾和恢复，因此 Spark 设计了一套别的方案来达到该目的，那就是 RDD + Lineage。RDD(Resilient Distribute Datasets)称为弹性数据集，它是一种对被操作数据的抽象，而 Lineage 称为“血统”，顾名思义它记录了每一个 RDD 演变过程中的上下文信息。当故障出现时，可以根据丢失的 RDD 的 Lineage 来追寻它的祖先 RDD ，然后重新执行演化即可恢复出丢失的 RDD。
二、Spark 编程模型
使用 Spark 的用户通过编写一个称为 Driver Program 的程序来实现自己的计算任务。Spark 为用户的并行化编程提供了三个组件：resilient distribution dataset、 parallel operations、 parallel operations。
(1) Resilient Distribution Datasets(RDDs)：一个 RDD 是一个可恢复的只读对象集合，它无须存储在磁盘中。每次对一个 RDD 的操作都会被记录下来，从而每个 RDD 可以沿着它的演化过程一直追寻它的祖先 RDD，甚至可以追寻到最开始的第一次从磁盘读取初始数据。因此这个机制保证了任何一个 RDD 都可以被恢复。具体在 Spark 系统中，RDD 由 Scala 对象来表达。论文中规定了 RDD 仅可以从四种方式构造：</div><div class="post-footer">
        <a href="/2019-05-09-%E8%AE%BA%E6%96%87-spark/">Read More</a></div>
</article>
<article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/2019-05-08-%E8%AE%BA%E6%96%87-mapreduce/">MapReduce</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>yusheng</a></span>&nbsp;<span class="post-publish">
            published on&nbsp;<time datetime=2019-05-08>2019-05-08</time>
        </span>&nbsp;
            <span class="post-category">included in<a href="/categories/thesis/">
                        <i class="far fa-folder fa-fw"></i>Thesis
                    </a></span></div><div class="content">一、背景及问题
这两天总算把谷歌三大论文之一的 MapReduce 看了。这篇论文的影响力就不多说了，谷歌AI首席科学家 Jeffrey Dean 的代表作之一。该论文主要提出了一个称为 MapReduce 的编程模型，主要是为了解决谷歌公司自身需要处理海量数据的问题。众所周知，谷歌的主要业务是搜索引擎，每天需要处理爬取到的海量文件和网页，以及对这些数据进行索引计算、处理查询请求等等。显然单台机器难以完成这样巨大的计算任务，必须使用机器集群。但如果使用专业的服务器，集群的成本就太高了。为了降低成本，谷歌采用了普通的计算机来搭建这个集群。为了实现这个目的，必须设计一套可以自动并行化计算、自我管理调度、以及拥有良好容错性的集群计算方案，因此 Jeffrey Dean 提出了这套编程模型，只要按照这个编程模型来调用接口实现计算任务，这些计算就可以自动地在一个由普通机器搭建的分布式集群上被并行地执行。
二、解决方案
具体来说，MapReduce 这个编程模型可以简单地分为 Map 部分以及 Reduce 部分。
Map 函数：由用户实现该接口，其功能是使算法输入的初始 key-value 对转化成用户定义的新 key-value 对。接下来系统会自动把它们按新 key 分组，即一个新 key 对应一组 values（key-values），并传递给 Reduce 函数。这一步类似 SQL 中的 Select GroupBy 操作。
$$key_{1}/value_{1} \implies key_{2}/value_{2} \implies key_{2}/value_{2}(s)$$
Reduce 函数：由用户实现该接口，其功能是使从 Map 函数接收过来的 key-values 组按用户定义的计算方式进行 Merge，然后输出每个 key 组的最终结果。这一步类似定义 SQL 中对被 GroupBy 的字段的聚合函数。
$$key_{2}/value_{2}(s) \implies key_{2}/value_{3} $$
论文中给出了一个具体例子，从一个巨大的文档集中统计每个单词的出现次数。每个单词可以看作 key，它的出现次数就是最终想得到的 value。按照 MapReduce 编程范式，可以分为两步，在 Map 阶段输入文档集合，为每个文档拆解出每个单词，并为每个单词赋值它的 value 为 1，表示这个单词在此出现了一次；在 Reduce 阶段，把每个单词对应的分组进行 value 的求和，即可得到每个单词的总出现次数。</div><div class="post-footer">
        <a href="/2019-05-08-%E8%AE%BA%E6%96%87-mapreduce/">Read More</a></div>
</article>
<article class="single summary" itemscope itemtype="http://schema.org/Article"><h1 class="single-title" itemprop="name headline">
        <a href="/2019-01-27-%E8%AE%BA%E6%96%87-mci/">MCI</a>
    </h1><div class="post-meta"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>yusheng</a></span>&nbsp;<span class="post-publish">
            published on&nbsp;<time datetime=2019-01-27>2019-01-27</time>
        </span>&nbsp;
            <span class="post-category">included in<a href="/categories/thesis/">
                        <i class="far fa-folder fa-fw"></i>Thesis
                    </a></span></div><div class="content">该文章依然是针对 APT 攻击而提出的一种基于模型推断的攻击因果分析。该方法比以往方法的优势在于不需要在系统中做任何修改，只需要启动日志，对系统事件进行记录即可。该方法的核心技术是使用一种称为 LDX 的动态分析方案，可以在系统调用之间进行因果推断。</div><div class="post-footer">
        <a href="/2019-01-27-%E8%AE%BA%E6%96%87-mci/">Read More</a></div>
</article>
<ul class="pagination"><li class="page-item active">
                    <span class="page-link">
                        <a href="/">1</a>
                    </span>
                </li><li class="page-item ">
                    <span class="page-link">
                        <a href="/page/2/">2</a>
                    </span>
                </li><li class="page-item ">
                    <span class="page-link">
                        <a href="/page/3/">3</a>
                    </span>
                </li><li class="page-item ">
                    <span class="page-link" aria-hidden="true">&hellip;</span>
                </li><li class="page-item ">
                    <span class="page-link">
                        <a href="/page/15/">15</a>
                    </span>
                </li></ul></div></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.69.2">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.6"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2019 - 2021</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">yusheng</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><script type="text/javascript">
    window.config = {"code":{"copyTitle":"Copy to clipboard","maxShownLines":100},"data":{"id-1":"Stay hungry, stay foolish."},"headerMode":{"desktop":"fixed","mobile":"auto"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"id-1":["id-1"]},"duration":-1,"speed":100}};
</script><script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=html5shiv%2CElement.prototype.closest%2CrequestAnimationFrame%2CCustomEvent%2CPromise%2CObject.entries%2CObject.assign%2CObject.values%2Cfetch%2CElement.prototype.after%2CArray.prototype.fill%2CIntersectionObserver%2CArray.from%2CArray.prototype.find%2CMath.sign"></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/object-fit-images/ofi.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/typeit/typeit.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
