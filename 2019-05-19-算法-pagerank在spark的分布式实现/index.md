# PageRank在Spark的分布式实现


最近在研究 MapReduce 和 Spark 的相关资料，顺便补个关于如何在虚拟机中搭建的 Spark 上分布式运行 PageRank 算法的博客。犹记得这个小任务是研一开学时，导师布置的第一个小任务，而现在马上就要硕士毕业答辩了，不禁思绪万千。

一、PageRank 算法

PageRank 算法是谷歌的起家算法，凭借该算法谷歌击败了当时所有的其他门户网站以及搜索引擎。该算法的目的是对数以亿计的网页进行排序，重要的网页将被排在前列，作为搜索结果返回给用户。想起了昆丁的电影《低俗小说》中的对白：“如果你要把一具尸体藏起来，你知道世界上哪里最安全吗？那就是谷歌搜索结果的第二页”。言外之意，谷歌搜索的前几条解决方案总能满足用户，用户永远不需要翻到第二页寻找答案。由此可见谷歌的搜索算法及 PageRank 网页排序算法之强大。

PageRank 算法的详细介绍见 [维基百科][1]。总而言之，该算法的主要思路是：如果一个网页被很多重要的网页指向，那么它也是一个重要的网页。具体地，互联网中的每个网页被抽象成一个节点；如果网页 A 包含网页 B 的链接，那么有一条有向边从节点 A 指向节点 B。如此，互联网中的网页及其链接被抽象成一个由节点及有向边组成的巨大拓扑图。

![](/2019-05-19-算法-PageRank在Spark的分布式实现/graph.jpg)

拓扑图建立好后，初始化系统，令每个节点的重要性分数均为1。然后开始迭代系统，在每一轮迭代中，对于每个节点，做如下两件事：

 - 如果出边是加权的，将该节点的分数按权重比例进行拆解并传送到对应的节点；如果出边不加权，那么将该节点的分数平均拆解并传送
 - 搜集从其他节点传送过来的分数并求和，替换该节点原来的分数

该过程从数学上来说就是一个 [马尔可夫过程][2]，可以从数学上证明其收敛性。也就是说，该系统经过若干次迭代，必定可以演化到一个平衡态。在这个状态下，每个节点的每一次分数收入约等于其分数支出。此时，每个节点上的分数就是稳定的分数，PageRank 算法按照该分数从大到小对网页进行排序并（分页地）返回给用户。

二、PageRank 算法的 Spark 分布式实现

输入数据是一个文件，如下所示。第一行只有一个数字，表明了该数据集一共有 114529 个网页节点。从第二行开始，每一行表示一个节点的出边以及对应的权重，以 [key-value] 形式表示 ：[指向的节点id:权重]。在使用该数据集时，需要把第一行的数字删去，刚好剩下一共 114529 行，每一行的行号表示其节点id。例如，删掉第一行后，第 2 行为空行，说明节点 2 出度为 0，不指向任何其他节点；第 3 行的数据表示节点 3 指向了节点 8107、节点 22950 和 节点 108053，边的权重分别为 3320、4 和 1。

![](/2019-05-19-算法-PageRank在Spark的分布式实现/data.png)

要分布式实现 PageRank，就需要按 MapReduce 编程范式来编写代码。MapReduce 接受的输入是 key-value 对，在 Map 过程中映射成新的 key-value 对，在 Reduce 过程中对相同 key 的 values 进行聚合，输入最终结果。为方便起见，使用函数式编程语言 Scala 编写。伪码如下：

```
输入数据(每行) noteId:[outlinkId1:weight1, outlinkedId2:weight2, ...]
预处理(每行) noteId:[outlinkId1, outlinkedId2, ...]
统计出度 [noteId1:outlinkCount1, noteId2:outlinkCount2, ...]
for 0 -> 迭代次数：
    拆分分数 [noteId1:contribution=score1/outlinkCount1, ...]
    收集分数 [noteId1:sum(inlinkIds:contributions), ...]
    归一化
打印显示每个节点的最终分数
```

具体实验代码及效果如下所示。

![](/2019-05-19-算法-PageRank在Spark的分布式实现/1.png)

![](/2019-05-19-算法-PageRank在Spark的分布式实现/2.png)

![](/2019-05-19-算法-PageRank在Spark的分布式实现/3.png)

按分数排序，并结合另一个数据集里面的 url 名称进行显示，得到结果如下所示。可以由域名看到排在前列的都是一些英国政府的权威网页（这个数据集是英国的网页数据集），因此该算法的排序效果是很好的。学术上更加具体的排序效果评价指标是 [nDCG][3]，这里不再展开说明了。

![](/2019-05-19-算法-PageRank在Spark的分布式实现/result.png)

  [1]: https://en.wikipedia.org/wiki/PageRank
  [2]: https://en.wikipedia.org/wiki/Markov_chain
  [3]: https://en.wikipedia.org/wiki/Discounted_cumulative_gain
 
 

