<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">

    <meta name="author" content="Yusheng Wang">
    <meta name="description" content="一、提升树（boosting tree）
提升树是以分类树或回归树为基本分类器的提升方法。提升树被认为是统计学习中性能最好的方法之一。提升方法采用加法模型（即基函数的线性组合）与前向分步算法。对分类问题，决策树是二叉分类树；对回归问题，决策树是二叉回归树。
提升树模型可以表示为决策树的加法模型：
$$f_M(x)=\sum_{m=1}^{M}T(x;\theta_m)$$
其中，$T(x;\theta_m)$ 表示决策树，$\theta_m$ 为决策树的参数，$M$ 为决策树的个数。
二、二分类问题的提升树
对于二分类问题，提升树算法只需将 Adaboost 算法中的基本分类器限制为二分类树即可。
目前比较流行的方案是采用一种简单决策树作为基本分类器：单层决策树（decision stump，也称决策树桩）。它仅仅基于单个特征来执行决策，因此对应地只有一个树结点：根节点。它只能执行一次二分类，如 $x &lt; v$ 或 $x &gt; v$。
三、回归问题的提升树
回归树的形式化描述：设训练数据集 $T={(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)}$，$x_i \in X \subseteq R^n$，$y_i \in Y \subseteq R$，$X$ 是输入空间，$Y$ 是输出空间。如果将输入空间 $X$ 划分为 $J$ 个不相交的区域 $R_1,R_2,\cdots,R_J$，并且在每个区域上有确定的输出常量 $c_j$，那么回归树可以表示为：
$$T(x;\theta)=\sum_{j=1}^{J}c_j \cdot I(x \in R_j)$$
其中，参数 $\theta={(R_1,c_1),(R_2,c_2),\cdots,(R_J,c_J)}$ 表示回归树的区域划分和各区域上的输出常量（即输出的回归值），$J$ 是回归树的复杂度（即叶结点个数）。
回归问题的提升树算法：
输入：如上，训练数据集 $T$，输入空间 $X$，输出空间 $Y$ 输出：回归提升树 $f_M(x)$
1、初始化 $f_0(x)=0$
2、对 $M$ 个分类器，进行对应的第 $m=1,2,\cdots,M$ 轮学习。对第 $m$ 轮学习：
(1)、计算以前一轮为止，目前学习到的回归提升树 $f_{m-1}(x)$ 的残差
$$r_{mi}=y_i-f_{m-1}(x_i)，i=1,2,\cdots,N$$">
    <meta name="keywords" content="blog,developer,personal">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="分类提升树与回归提升树"/>
<meta name="twitter:description" content="一、提升树（boosting tree）
提升树是以分类树或回归树为基本分类器的提升方法。提升树被认为是统计学习中性能最好的方法之一。提升方法采用加法模型（即基函数的线性组合）与前向分步算法。对分类问题，决策树是二叉分类树；对回归问题，决策树是二叉回归树。
提升树模型可以表示为决策树的加法模型：
$$f_M(x)=\sum_{m=1}^{M}T(x;\theta_m)$$
其中，$T(x;\theta_m)$ 表示决策树，$\theta_m$ 为决策树的参数，$M$ 为决策树的个数。
二、二分类问题的提升树
对于二分类问题，提升树算法只需将 Adaboost 算法中的基本分类器限制为二分类树即可。
目前比较流行的方案是采用一种简单决策树作为基本分类器：单层决策树（decision stump，也称决策树桩）。它仅仅基于单个特征来执行决策，因此对应地只有一个树结点：根节点。它只能执行一次二分类，如 $x &lt; v$ 或 $x &gt; v$。
三、回归问题的提升树
回归树的形式化描述：设训练数据集 $T={(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)}$，$x_i \in X \subseteq R^n$，$y_i \in Y \subseteq R$，$X$ 是输入空间，$Y$ 是输出空间。如果将输入空间 $X$ 划分为 $J$ 个不相交的区域 $R_1,R_2,\cdots,R_J$，并且在每个区域上有确定的输出常量 $c_j$，那么回归树可以表示为：
$$T(x;\theta)=\sum_{j=1}^{J}c_j \cdot I(x \in R_j)$$
其中，参数 $\theta={(R_1,c_1),(R_2,c_2),\cdots,(R_J,c_J)}$ 表示回归树的区域划分和各区域上的输出常量（即输出的回归值），$J$ 是回归树的复杂度（即叶结点个数）。
回归问题的提升树算法：
输入：如上，训练数据集 $T$，输入空间 $X$，输出空间 $Y$ 输出：回归提升树 $f_M(x)$
1、初始化 $f_0(x)=0$
2、对 $M$ 个分类器，进行对应的第 $m=1,2,\cdots,M$ 轮学习。对第 $m$ 轮学习：
(1)、计算以前一轮为止，目前学习到的回归提升树 $f_{m-1}(x)$ 的残差
$$r_{mi}=y_i-f_{m-1}(x_i)，i=1,2,\cdots,N$$"/>

    <meta property="og:title" content="分类提升树与回归提升树" />
<meta property="og:description" content="一、提升树（boosting tree）
提升树是以分类树或回归树为基本分类器的提升方法。提升树被认为是统计学习中性能最好的方法之一。提升方法采用加法模型（即基函数的线性组合）与前向分步算法。对分类问题，决策树是二叉分类树；对回归问题，决策树是二叉回归树。
提升树模型可以表示为决策树的加法模型：
$$f_M(x)=\sum_{m=1}^{M}T(x;\theta_m)$$
其中，$T(x;\theta_m)$ 表示决策树，$\theta_m$ 为决策树的参数，$M$ 为决策树的个数。
二、二分类问题的提升树
对于二分类问题，提升树算法只需将 Adaboost 算法中的基本分类器限制为二分类树即可。
目前比较流行的方案是采用一种简单决策树作为基本分类器：单层决策树（decision stump，也称决策树桩）。它仅仅基于单个特征来执行决策，因此对应地只有一个树结点：根节点。它只能执行一次二分类，如 $x &lt; v$ 或 $x &gt; v$。
三、回归问题的提升树
回归树的形式化描述：设训练数据集 $T={(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)}$，$x_i \in X \subseteq R^n$，$y_i \in Y \subseteq R$，$X$ 是输入空间，$Y$ 是输出空间。如果将输入空间 $X$ 划分为 $J$ 个不相交的区域 $R_1,R_2,\cdots,R_J$，并且在每个区域上有确定的输出常量 $c_j$，那么回归树可以表示为：
$$T(x;\theta)=\sum_{j=1}^{J}c_j \cdot I(x \in R_j)$$
其中，参数 $\theta={(R_1,c_1),(R_2,c_2),\cdots,(R_J,c_J)}$ 表示回归树的区域划分和各区域上的输出常量（即输出的回归值），$J$ 是回归树的复杂度（即叶结点个数）。
回归问题的提升树算法：
输入：如上，训练数据集 $T$，输入空间 $X$，输出空间 $Y$ 输出：回归提升树 $f_M(x)$
1、初始化 $f_0(x)=0$
2、对 $M$ 个分类器，进行对应的第 $m=1,2,\cdots,M$ 轮学习。对第 $m$ 轮学习：
(1)、计算以前一轮为止，目前学习到的回归提升树 $f_{m-1}(x)$ 的残差
$$r_{mi}=y_i-f_{m-1}(x_i)，i=1,2,\cdots,N$$" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://utopizza.github.io/posts/machinelearning/2017-11-26-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%88%86%E7%B1%BB%E6%8F%90%E5%8D%87%E6%A0%91%E4%B8%8E%E5%9B%9E%E5%BD%92%E6%8F%90%E5%8D%87%E6%A0%91/" />
<meta property="article:published_time" content="2017-11-26T14:40:00+00:00" />
<meta property="article:modified_time" content="2017-11-26T14:40:00+00:00" />


    
      <base href="https://utopizza.github.io/posts/machinelearning/2017-11-26-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%88%86%E7%B1%BB%E6%8F%90%E5%8D%87%E6%A0%91%E4%B8%8E%E5%9B%9E%E5%BD%92%E6%8F%90%E5%8D%87%E6%A0%91/">
    
    <title>
  分类提升树与回归提升树 · Utopizza
</title>

    
      <link rel="canonical" href="https://utopizza.github.io/posts/machinelearning/2017-11-26-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%88%86%E7%B1%BB%E6%8F%90%E5%8D%87%E6%A0%91%E4%B8%8E%E5%9B%9E%E5%BD%92%E6%8F%90%E5%8D%87%E6%A0%91/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css" integrity="sha384-Bfad6CLCknfcloXFOyFnlgtENryhrpZCe29RTifKEixXQZ38WheV+i/6YWSzkz3V" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="https://utopizza.github.io/css/coder.min.a4f332213a21ce8eb521670c614470c58923aaaf385e2a73982c31dd7642decb.css" integrity="sha256-pPMyITohzo61IWcMYURwxYkjqq84XipzmCwx3XZC3ss=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="https://utopizza.github.io/css/coder-dark.min.e78e80fc3a585a4d1c8fc7f58623b6ff852411e38431a9cd1792877ecaa160f6.css" integrity="sha256-546A/DpYWk0cj8f1hiO2/4UkEeOEManNF5KHfsqhYPY=" crossorigin="anonymous" media="screen" />
      
    

    

    

    <link rel="icon" type="image/png" href="https://utopizza.github.io/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://utopizza.github.io/images/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.69.2" />
  </head>

  
  
    
  
  <body class="colorscheme-auto">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="https://utopizza.github.io/">
      Utopizza
    </a>
    
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://utopizza.github.io/about/">About</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://utopizza.github.io/posts/">Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://utopizza.github.io/projects/">Projects</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://utopizza.github.io/contact/">Contact me</a>
          </li>
        
      
      
    </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">分类提升树与回归提升树</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2017-11-26T14:40:00Z'>
                November 26, 2017
              </time>
            </span>
            <span class="reading-time">
              <i class="fas fa-clock"></i>
              1-minute read
            </span>
          </div>
          <div class="categories">
  <i class="fas fa-folder"></i>
    <a href="https://utopizza.github.io/categories/machinelearning/">MachineLearning</a></div>

          
        </div>
      </header>

      <div>
        
        <p>一、提升树（boosting tree）</p>
<p>提升树是以<strong>分类树</strong>或<strong>回归树</strong>为<strong>基本分类器</strong>的提升方法。提升树被认为是统计学习中性能最好的方法之一。提升方法采用加法模型（即基函数的线性组合）与前向分步算法。对分类问题，决策树是二叉分类树；对回归问题，决策树是二叉回归树。</p>
<p>提升树模型可以表示为决策树的加法模型：</p>
<p>$$f_M(x)=\sum_{m=1}^{M}T(x;\theta_m)$$</p>
<p>其中，$T(x;\theta_m)$ 表示决策树，$\theta_m$ 为决策树的参数，$M$ 为决策树的个数。</p>
<p>二、二分类问题的提升树</p>
<p>对于二分类问题，提升树算法只需将 Adaboost 算法中的基本分类器限制为二分类树即可。</p>
<p>目前比较流行的方案是采用一种简单决策树作为基本分类器：单层决策树（decision stump，也称决策树桩）。它仅仅基于单个特征来执行决策，因此对应地只有一个树结点：根节点。它只能执行一次二分类，如 $x &lt; v$ 或 $x &gt; v$。</p>
<p>三、回归问题的提升树</p>
<p>回归树的形式化描述：设训练数据集 $T={(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)}$，$x_i \in X \subseteq R^n$，$y_i \in Y \subseteq R$，$X$ 是输入空间，$Y$ 是输出空间。如果将输入空间 $X$ 划分为 $J$ 个不相交的区域 $R_1,R_2,\cdots,R_J$，并且在每个区域上有确定的输出常量 $c_j$，那么回归树可以表示为：</p>
<p>$$T(x;\theta)=\sum_{j=1}^{J}c_j \cdot I(x \in R_j)$$</p>
<p>其中，参数 $\theta={(R_1,c_1),(R_2,c_2),\cdots,(R_J,c_J)}$ 表示回归树的区域划分和各区域上的输出常量（即输出的回归值），$J$ 是回归树的复杂度（即<strong>叶结点</strong>个数）。</p>
<p>回归问题的提升树算法：</p>
<p>输入：如上，训练数据集 $T$，输入空间 $X$，输出空间 $Y$
输出：回归提升树 $f_M(x)$</p>
<p>1、初始化 $f_0(x)=0$</p>
<p>2、对 $M$ 个分类器，进行对应的第 $m=1,2,\cdots,M$ 轮学习。对第 $m$ 轮学习：</p>
<p>(1)、计算以前一轮为止，目前学习到的回归提升树 $f_{m-1}(x)$ 的残差</p>
<p>$$r_{mi}=y_i-f_{m-1}(x_i)，i=1,2,\cdots,N$$</p>
<p>(2)、拟合残差 $r_{mi}$ 学习得到第 $m$ 个回归树 $T(x;\theta_m)$</p>
<p>(3)、把该回归树加入 $f_{m-1}(x)$，得到新的回归提升树</p>
<p>$$f_m(x)=f_{m-1}(x)+T(x;\theta_m)$$</p>
<p>3、执行完 $M$ 轮学习后，得到最终的回归提升树</p>
<p>$$f_M(x)=\sum_{m=1}^{M}T(x;\theta_m)$$</p>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

      </div>

      <script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

    </main>

    

    

    <script>
(function(f, a, t, h, o, m){
	a[h]=a[h]||function(){
		(a[h].q=a[h].q||[]).push(arguments)
	};
	o=f.createElement('script'),
	m=f.getElementsByTagName('script')[0];
	o.async=1; o.src=t; o.id='fathom-script';
	m.parentNode.insertBefore(o,m)
})(document, window, '//analytics.example.com/tracker.js', 'fathom');
fathom('set', 'siteId', 'ABCDE');
fathom('trackPageview');
</script>


  </body>

</html>
