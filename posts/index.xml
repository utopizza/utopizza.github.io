<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>All Posts - Utopizza</title>
        <link>https://utopizza.github.io/posts/</link>
        <description>All Posts | Utopizza</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>648847079@qq.com (yusheng)</managingEditor>
            <webMaster>648847079@qq.com (yusheng)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Mon, 16 Sep 2019 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://utopizza.github.io/posts/" rel="self" type="application/rss+xml" /><item>
    <title>阶段总结(8)</title>
    <link>https://utopizza.github.io/2019-09-16-%E6%80%BB%E7%BB%93-%E9%98%B6%E6%AE%B5%E6%80%BB%E7%BB%938/</link>
    <pubDate>Mon, 16 Sep 2019 00:00:00 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://utopizza.github.io/2019-09-16-%E6%80%BB%E7%BB%93-%E9%98%B6%E6%AE%B5%E6%80%BB%E7%BB%938/</guid>
    <description><![CDATA[上一次写阶段总结是2019年4月30日，距现在已经过去了5、6、7、8四个月。需要总结下这四个月以来的工作，以及后续的计划。
一、Backward
2019年5月 毕业答辩日期安排在5月26日，因此这个月基本全部精力时间都花在论文上。论文主体在4月份基本已经写完了，5月份基本都是在补一些报告书如开题报告、中期检查报告等等。月初和舍友去木兰天池玩了一天，山上挺凉快的。中间抽时间在宿舍看了一部电视剧《我们离恶有多远》，相当震撼，因为剧中探讨的问题十分有深度。剧情比较虐心，让人看得都郁闷了很久。就这样刷刷剧、写写文档，就浑浑噩噩到了答辩日期。答辩地点就在实验室旁边的一个大会议室，但是评委老师一个都没见过，刚开始还是有点紧张的。由于准备还算较充分，流畅地讲完了PPT，评委老师也没问什么很深入的问题，就问了我在汉口那边呆了多久，什么时候回来的。我说3月回来的，老师还表扬了一波我说这么短时间能弄出这么多公式理论，还不错。。大概就是就这样水过了硕士答辩。硕士阶段的最后一块大石终于落地。答辩完了基本就知道通过了。回去的路上，感觉整个世界都不一样，虽然是下午四点多，但是感觉阳光特别特别的明媚。
2019年6月 答辩完了之后，回去就是整理各种报告、文档，然后去打印店打印封装论文。然后就是各种浪了，约几个小伙伴一起去游泳、密室逃脱、攀岩、射箭、桌游、吃吃喝喝。月初端午节百度寄来了一箱很粽子，16号的时候学校还举办了毕业晚餐会。18号晚上老爸老妈到汉，带他们吃了西餐，然后安顿好酒店。19号带他们逛了武大、省博、楚河汉街。20号上午是毕业典礼，下午弄离校手续，旁晚去拍了毕业照。21号主要是收拾宿舍东西，寄东西，下午带爸妈去逛光谷、拍照。晚上和舍友聚餐。22号早上等爸妈过来吃了早饭，就跟舍友告别，滴滴去高铁站了。
2019年7月、8月、9月 系统里定的7月10号报到入职，因此在家里只呆了不到两周就上深圳了。刚入职就遇到团建——东西冲穿越，不知道是暴晒的原因还是过度运动的原因，回来竟然发烧、鼻炎复发。先后看了两次医生，做了鼻镜检查，浪费了不少时间，不过还好没事。从7月10号入职到现在，这两个月的主要工作任务就是看文档和内部的wiki，熟悉团队的产品。还有一些小issue需要写一些简单的代码，难度不大。另外还有一些运维和运营的小任务，就是平时要留意下一些服务的监控任务的报警，根据情况处理下就行，也不太难。总的来说目前主要是以熟悉和了解为主，辅以一些小issue开发任务，还有各种新人培训课程。公司也配备了导师，感觉导师的指导还是非常到位的，尤其一开始就指出要从校园心态过渡到职场心态，我一开始听了没什么感觉，但是到了后来就确实体会到了，确实比较难一下子调整过来。
二、forward
最近想了下，工作之余应该有自己的学习计划和安排，否则会浪费很多时间。因此制作个最近的一些学习小目标吧：
 代码规范：这是工程师的最基本素养（python已看，java未看） 多看代码，总结设计模式：同为最基本素养之一 学习大数据组件：hadoop，spark，storm，kafka，zookeeper，flume，thrift，protobuf 学习虚拟化组件：docker，k8s 学会使用上述组件之后，进行源码学习，尝试在git中进行contribute，争取被accept leetcode要重新开始刷，每天至少一道到两道 学有余力的话，学习新语言：mapreduce，storm topology，golang 英语单词落下一段时间了，要重启百词斩和听力练习了 关注下hk的实验室和团队，还有research方向 坚持锻炼身体  目前只想到这么些。目前学习的方式要转变，万事先看官网，快速了解产品的背景、解决的问题、基本框架、基本使用方法，然后下载到本地安装，跑一些小demo。另外一些零碎时间也应该利用起来，背单词或者思考算法题都行。]]></description>
</item><item>
    <title>PageRank在Spark的分布式实现</title>
    <link>https://utopizza.github.io/2019-05-19-%E7%AE%97%E6%B3%95-pagerank%E5%9C%A8spark%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E7%8E%B0/</link>
    <pubDate>Sun, 19 May 2019 00:00:00 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://utopizza.github.io/2019-05-19-%E7%AE%97%E6%B3%95-pagerank%E5%9C%A8spark%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E7%8E%B0/</guid>
    <description><![CDATA[最近在研究 MapReduce 和 Spark 的相关资料，顺便补个关于如何在虚拟机中搭建的 Spark 上分布式运行 PageRank 算法的博客。犹记得这个小任务是研一开学时，导师布置的第一个小任务，而现在马上就要硕士毕业答辩了，不禁思绪万千。
一、PageRank 算法
PageRank 算法是谷歌的起家算法，凭借该算法谷歌击败了当时所有的其他门户网站以及搜索引擎。该算法的目的是对数以亿计的网页进行排序，重要的网页将被排在前列，作为搜索结果返回给用户。想起了昆丁的电影《低俗小说》中的对白：“如果你要把一具尸体藏起来，你知道世界上哪里最安全吗？那就是谷歌搜索结果的第二页”。言外之意，谷歌搜索的前几条解决方案总能满足用户，用户永远不需要翻到第二页寻找答案。由此可见谷歌的搜索算法及 PageRank 网页排序算法之强大。
PageRank 算法的详细介绍见 维基百科。总而言之，该算法的主要思路是：如果一个网页被很多重要的网页指向，那么它也是一个重要的网页。具体地，互联网中的每个网页被抽象成一个节点；如果网页 A 包含网页 B 的链接，那么有一条有向边从节点 A 指向节点 B。如此，互联网中的网页及其链接被抽象成一个由节点及有向边组成的巨大拓扑图。
拓扑图建立好后，初始化系统，令每个节点的重要性分数均为1。然后开始迭代系统，在每一轮迭代中，对于每个节点，做如下两件事：
 如果出边是加权的，将该节点的分数按权重比例进行拆解并传送到对应的节点；如果出边不加权，那么将该节点的分数平均拆解并传送 搜集从其他节点传送过来的分数并求和，替换该节点原来的分数  该过程从数学上来说就是一个 马尔可夫过程，可以从数学上证明其收敛性。也就是说，该系统经过若干次迭代，必定可以演化到一个平衡态。在这个状态下，每个节点的每一次分数收入约等于其分数支出。此时，每个节点上的分数就是稳定的分数，PageRank 算法按照该分数从大到小对网页进行排序并（分页地）返回给用户。
二、PageRank 算法的 Spark 分布式实现
输入数据是一个文件，如下所示。第一行只有一个数字，表明了该数据集一共有 114529 个网页节点。从第二行开始，每一行表示一个节点的出边以及对应的权重，以 [key-value] 形式表示 ：[指向的节点id:权重]。在使用该数据集时，需要把第一行的数字删去，刚好剩下一共 114529 行，每一行的行号表示其节点id。例如，删掉第一行后，第 2 行为空行，说明节点 2 出度为 0，不指向任何其他节点；第 3 行的数据表示节点 3 指向了节点 8107、节点 22950 和 节点 108053，边的权重分别为 3320、4 和 1。
要分布式实现 PageRank，就需要按 MapReduce 编程范式来编写代码。MapReduce 接受的输入是 key-value 对，在 Map 过程中映射成新的 key-value 对，在 Reduce 过程中对相同 key 的 values 进行聚合，输入最终结果。为方便起见，使用函数式编程语言 Scala 编写。伪码如下：]]></description>
</item><item>
    <title>Spark</title>
    <link>https://utopizza.github.io/2019-05-09-thesis-spark/</link>
    <pubDate>Thu, 09 May 2019 00:00:00 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://utopizza.github.io/2019-05-09-thesis-spark/</guid>
    <description><![CDATA[一、背景及问题
在谷歌提出了 MapReduce 编程模型之后，UC Berkeley 在此基础上提出了一个更加高效的模型，称为 Spark。其核心思想是将 MapReduce 的中间结果缓存到内存中，使得 Workers 可以快速读取数据而无需启动延迟极大的磁盘读取操作。这种编程模型针对一些迭代次数高、需要反复使用或者修改数据的计算任务尤其有效。根据论文的实验，Spark 在一些高迭代次数的算法实验中处理速度是 MapReduce 的 10 倍以上。
然而因为没有了将中间结果写磁盘的操作来保证容灾和恢复，因此 Spark 设计了一套别的方案来达到该目的，那就是 RDD + Lineage。RDD(Resilient Distribute Datasets)称为弹性数据集，它是一种对被操作数据的抽象，而 Lineage 称为“血统”，顾名思义它记录了每一个 RDD 演变过程中的上下文信息。当故障出现时，可以根据丢失的 RDD 的 Lineage 来追寻它的祖先 RDD ，然后重新执行演化即可恢复出丢失的 RDD。
二、Spark 编程模型
使用 Spark 的用户通过编写一个称为 Driver Program 的程序来实现自己的计算任务。Spark 为用户的并行化编程提供了三个组件：resilient distribution dataset、 parallel operations、 parallel operations。
(1) Resilient Distribution Datasets(RDDs)：一个 RDD 是一个可恢复的只读对象集合，它无须存储在磁盘中。每次对一个 RDD 的操作都会被记录下来，从而每个 RDD 可以沿着它的演化过程一直追寻它的祖先 RDD，甚至可以追寻到最开始的第一次从磁盘读取初始数据。因此这个机制保证了任何一个 RDD 都可以被恢复。具体在 Spark 系统中，RDD 由 Scala 对象来表达。论文中规定了 RDD 仅可以从四种方式构造：]]></description>
</item><item>
    <title>MapReduce</title>
    <link>https://utopizza.github.io/2019-05-08-%E8%AE%BA%E6%96%87-mapreduce/</link>
    <pubDate>Wed, 08 May 2019 00:00:00 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://utopizza.github.io/2019-05-08-%E8%AE%BA%E6%96%87-mapreduce/</guid>
    <description><![CDATA[一、背景及问题
这两天总算把谷歌三大论文之一的 MapReduce 看了。这篇论文的影响力就不多说了，谷歌AI首席科学家 Jeffrey Dean 的代表作之一。该论文主要提出了一个称为 MapReduce 的编程模型，主要是为了解决谷歌公司自身需要处理海量数据的问题。众所周知，谷歌的主要业务是搜索引擎，每天需要处理爬取到的海量文件和网页，以及对这些数据进行索引计算、处理查询请求等等。显然单台机器难以完成这样巨大的计算任务，必须使用机器集群。但如果使用专业的服务器，集群的成本就太高了。为了降低成本，谷歌采用了普通的计算机来搭建这个集群。为了实现这个目的，必须设计一套可以自动并行化计算、自我管理调度、以及拥有良好容错性的集群计算方案，因此 Jeffrey Dean 提出了这套编程模型，只要按照这个编程模型来调用接口实现计算任务，这些计算就可以自动地在一个由普通机器搭建的分布式集群上被并行地执行。
二、解决方案
具体来说，MapReduce 这个编程模型可以简单地分为 Map 部分以及 Reduce 部分。
Map 函数：由用户实现该接口，其功能是使算法输入的初始 key-value 对转化成用户定义的新 key-value 对。接下来系统会自动把它们按新 key 分组，即一个新 key 对应一组 values（key-values），并传递给 Reduce 函数。这一步类似 SQL 中的 Select GroupBy 操作。
$$key_{1}/value_{1} \implies key_{2}/value_{2} \implies key_{2}/value_{2}(s)$$
Reduce 函数：由用户实现该接口，其功能是使从 Map 函数接收过来的 key-values 组按用户定义的计算方式进行 Merge，然后输出每个 key 组的最终结果。这一步类似定义 SQL 中对被 GroupBy 的字段的聚合函数。
$$key_{2}/value_{2}(s) \implies key_{2}/value_{3} $$
论文中给出了一个具体例子，从一个巨大的文档集中统计每个单词的出现次数。每个单词可以看作 key，它的出现次数就是最终想得到的 value。按照 MapReduce 编程范式，可以分为两步，在 Map 阶段输入文档集合，为每个文档拆解出每个单词，并为每个单词赋值它的 value 为 1，表示这个单词在此出现了一次；在 Reduce 阶段，把每个单词对应的分组进行 value 的求和，即可得到每个单词的总出现次数。]]></description>
</item><item>
    <title>阶段总结(7)</title>
    <link>https://utopizza.github.io/2019-04-30-%E6%80%BB%E7%BB%93-%E9%98%B6%E6%AE%B5%E6%80%BB%E7%BB%937/</link>
    <pubDate>Tue, 30 Apr 2019 00:00:00 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://utopizza.github.io/2019-04-30-%E6%80%BB%E7%BB%93-%E9%98%B6%E6%AE%B5%E6%80%BB%E7%BB%937/</guid>
    <description><![CDATA[上一次写阶段总结是2018年10月，转眼过了半年多。自从10月份定了工作后，就转去忙论文、数学、以及英语。
一、论文
因为之前看过十来篇兴趣点推荐相关的顶会论文，考虑了下就还是继续做这个方向。从10月份开始，断断续续开始重新看了一遍之前看过的论文，以及做过的笔记和思路。因为之前专注于找工作，从4月份到9月份一直都是在看CS基础以及研发技术相关的书，学术工作放下了半年多，很多细节都忘记了。幸好之前认真做了笔记，复习起来不是太吃力。花了大约一星期的上午完成了复习，感觉还是没啥新灵感，继续用dblp去找了很多新的论文来看。印象中大概一直到快要放寒假的时候才想出了一个基本的雏形，用英文写了个小论文版本。寒假放了13天（2月1日到13日），在家基本都是休息，也没继续弄论文。回来后在公司陆续完成了论文的后半部分。思路基本是定下来了，给这边的老师看了下，确定思路没啥问题后，就差不多搬回学校了（3月3日）。
搬回学校之后就开始做实验，幸亏舍友给力，提供了他们实验室的服务器，不然我这小破笔记本完全不可能做的出实验。实验基本代码很快就写出来了，大概三天左右，接下来就是无尽的噩梦般的炼丹（调参）了。不知道是代码写错还是啥原因，我发现很有的参数即使是很小的改变，竟然对实验结果的影响很大（大雾）。到了三月中下旬，实验结果调得差不多之后，就感觉开始写大论文（毕业论文）。因为你之前已经写好了英文版的小论文，所以大论文写起来比较轻松，一共只用了6天左右。其中花的时间比较多的是第一章绪论，扯了很多废话，找了一些中文的参考文献。后面的相关理论、自己提出的模型、实验设计等等几章直接从英文小论文翻译下扩充下，雏形就基本出来了。四月份基本都在学校修修补补论文以及继续调参，还有就是考虑优化实验里的SGD。四月底，定了稿，发给了导师，以及回公司找导师签字一些报告。
总的来说，10月份主要复习以前看过的论文，11、12月看新论文，1月份开始构思自己的模型，以及写出一个基本的英语小论文雏形。2月份中旬寒假回来后继续完善英文小论文，2月底跟导师确认思路没有问题之后，3月初搬回学校。3月份开始做实验。3月中下旬用一周写出了大论文。4月份继续修补大论文以及实验调参。4月底定稿。
二、数学
因为比较闲，回头复习了一波微积分、线性代数、概率统计。其中，微积分主要通过复习本科时候学的《高等数学》，线性代数主要通过网上的教学视频以及研究生学的《矩阵论》，概率统计看的是中科大的《概率论与数理统计》。一般是晚上下班回去看书和吃饭的时候看视频，算是一个小复习。下面贴出资料链接。
 《高等数学》 《概率论与数理统计》 《矩阵论》 MIT公开课：线性代数 MIT公开课：微积分重点 3b1b：线性代数的本质 3b1b：微积分的本质  总的来说，11月、12月、1月这三个月的数学复习主要以晚上回宿舍看书为主，最后整理了大概9篇 博客。
三、英语
除了复习数学之外，也把英语提上了日程。除了平时看看美剧和google查资料之外，高考之后都几乎没碰过英语了。定了个考雅思的目标，因此开始找了一些资料，也问同学朋友找了些资料。从10月到12月三个月基本上都是在背四六级词汇，新东方的红书。因为习惯了这个系列的排版，索性就又买了这个系列的雅思词汇。背单词的同时也注意听力和写作。针对听力，主要就是直接听真题听力，把MP3下载到音乐播放软件，整天整夜没完没了地放。至于写作，买了本写作的书和一本笔记本，每天抄一篇范文，然后读几遍。从3月份搬回学校之后，因为每天去图书馆，就很少读英语范文了。该成用百词斩背单词。另外网上找到一个可以在线测试雅思水平的网站，虽然蛮多BUG。下面贴出资料。
 《新东方雅思词汇》 《顾家北手把手教你雅思写作》 雅思在线 词汇量测试  总的来说，这几个月基本把四六级背得比较熟了，雅思那本过了两三遍，词汇量在上面的网上测是9000个左右，百词斩测是一万个左右。搬回学校前主要以背单词书、抄写范文为主。搬回学校后以刷百词斩复习、在网上做雅思题为主。因为回学校后做论文实验花了很多时间，分配给英语的时间不是很多，练的比较少，目前效果不太理想。现在论文定了稿，后面重新把英语提上日程。]]></description>
</item><item>
    <title>MCI</title>
    <link>https://utopizza.github.io/2019-01-27-%E8%AE%BA%E6%96%87-mci/</link>
    <pubDate>Sun, 27 Jan 2019 00:00:00 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://utopizza.github.io/2019-01-27-%E8%AE%BA%E6%96%87-mci/</guid>
    <description><![CDATA[该文章依然是针对 APT 攻击而提出的一种基于模型推断的攻击因果分析。该方法比以往方法的优势在于不需要在系统中做任何修改，只需要启动日志，对系统事件进行记录即可。该方法的核心技术是使用一种称为 LDX 的动态分析方案，可以在系统调用之间进行因果推断。]]></description>
</item><item>
    <title>Oblix</title>
    <link>https://utopizza.github.io/2019-01-19-%E8%AE%BA%E6%96%87-oblix/</link>
    <pubDate>Sat, 19 Jan 2019 00:00:00 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://utopizza.github.io/2019-01-19-%E8%AE%BA%E6%96%87-oblix/</guid>
    <description><![CDATA[一、背景及问题
索引（Index）是很多系统和应用的基础构件。最近，大量的研究专注于如何保护索引这样的敏感数据，例如，如何在对索引进行加密的同时允许客户端在索引上进行查询。这些研究提出的方案一般是这样的：当用户通过客户端发起查询请求时，客户端会先为用户输入的关键词（keyword）生成查询令牌(search token)，然后将令牌发送给服务端而不是直接发送用户的关键词，从而向服务端屏蔽用户输入的关键词（假设攻击者控制了服务端的内存，但不能控制服务端的处理器）。然后，服务器通过令牌去在已经加密的索引上执行检索，最后把匹配成功的加密数据返回给客户端。客户端对数据进行解密，显示给用户。
虽然加密索引的研究取得了重大进步，但是很多方案都有一个很严重的漏洞，就是泄漏了存取模式（access patterns）：关键词与数据的匹配过程。虽然关键词和索引都是已经加密的，但是它们的匹配过程是在服务端的内存进行的，而服务端的内存是被攻击者掌控的，因此攻击者可以对匹配的过程进行分析，从而从加密的索引中恢复敏感信息。除了存取模式的遗漏，还有如果攻击者可以获得匹配成功的文件数（result size），也可以恢复出敏感信息。
一种很直接的隐藏存取模式的方法就是使用 ORAM（Oblivious RAM），然而这个方案的成本十分昂贵，因此很少方案采用这个方法。针对这个问题，文章提出了一个称为 Oblix (OBLivious IndeX) 的索引方案，这个方案既不会泄漏任何的存取模式，也不会泄漏匹配文件数。进一步，Oblix 允许索引进行插入和删除、支持多用户。
二、解决方案
文章提出的 Oblix 主要针对以下四种问题进行解决：
1、高复杂度：对于 ORAM 系统，客户端维护一个位置映射数据结构（position map），该数据结构记录了索引与数据库中某个数据的位置的对应关系。由于索引的大小与数据库的数据量成线性关系，因此客户端不能直接存储整个 map。一种标准的方案是使用树形结构将一个数据库分解成多级数据库（类似于多级索引），以减小客户端需要的存储空间。但是如此一来就会需要重复多次查询来确定最终的位置，显然树搜索的时间复杂度是 O(logN)，这样的复杂度会带来查询延迟。文章使用的解决方案是使用飞地技术（enclave），把整个 ORAM 的客户端放进飞地中，这样让客户端和服务端就在同一台机器上进行，不需要通过网络，从而减小网络延迟。
2、飞地可能会被攻击者利用：有研究发现飞地即使物理上隔离了外界的控制，但是也可能被攻击者通过分析它的物理页级的存取模式（page-level access pattern）来恢复被加密的数据。因为飞地自身的内存空间很小，当飞地处理的数据量较大时，它就会使用二级存储，使用计算机中的内存。而计算机中的内存是会被攻击者控制的，因此攻击者可以通过观察飞地如果使用计算机主存来进行攻击。文章的解决方案：首先，提出一个称为 ODS (oblivious data structure) 的数据结构来取代 position map，这个数据结构保证不可被攻击者利用。其次，提出一个称为 doubly oblivious 的方案，该方案同时保证对服务端的存取、对客户端自己的内存空间的存取模式都是不可被攻击者利用的（oblivious）。
3、查询结果数的隐藏：前面提到，查询结果数可能也会被攻击者用，因此需要对其进行隐藏。一种最简单的做法是“worst-case upper bound”，但是这种做法代价太昂贵。文章提出的解决方案：对查询结果进行打分排序，只返回得分最高的前 r 条数据。
4、请求列表、查询效率：客户端可以一次向服务端发送多个请求，也就请求列表。特别地，其中包含插入和删除得操作时，执行效率就尤其重要。文章解决方案：提出一个称为 DOSM (doubly-oblivious sorted multimap) 的数据结构，支持高效的范围查询、插入、删除等操作。它实际上是一个树形的数据结构，插入和删除的复杂度是 O(logN) 而不是 O(n)。另外再结合特定的查询算法来保证范围查询的高效性。
三、总结
文章主要针对存取模式的漏洞来进行修复。攻击虽然无法直接攻击飞地，无法直接攻击加密数据，但是可以通过应用对主存的存取模式进行分析从而恢复加密数据。这种存取模式在文章中是指例如索引这样的负责映射数据的数据结构。]]></description>
</item><item>
    <title>一维随机变量</title>
    <link>https://utopizza.github.io/2019-01-16-%E6%A6%82%E7%8E%87-%E4%B8%80%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F/</link>
    <pubDate>Wed, 16 Jan 2019 00:00:00 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://utopizza.github.io/2019-01-16-%E6%A6%82%E7%8E%87-%E4%B8%80%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F/</guid>
    <description><![CDATA[一、随机变量 随机变量就是“其值随机会而定”的变量。随机变量主要分为两类，一类是离散型随机变量，它有若干个不同的可枚举的取值，这些取值以不同（或相同）的概率出现，例如扔一个骰子可能会出现的点数。另一类是连续型随机变量，它的全部可能取值不仅是无穷多的，并且还不能无遗漏地逐一排列，而是充满一个区间，例如称量一个物体重量的误差。
二、离散型随机变量 1、离散型随机变量的概率分布：设 $X$ 为离散型随机变量，其全部可能取值 ${a_1,a_2,\cdots}$。则
$$p_i=P(X=a_i) \quad (i=1,2,\cdots)$$
称为 $X$ 的概率分布。根据概率的定义，显然有
$$p_i \geq 0$$
$$p_1+p_2+\cdots=1$$
用分布表的形式给出为
 $$ \begin{array}{c|lcr} \text{可能值} & a_1 & a_2 & \cdots & a_i \cdots \\ \hline \text{概率} & p_1 & p_2 & \cdots &p_i \cdots \end{array} $$  2、离散型随机变量的分布函数：设 $X$ 为一离散型随机变量，则函数
$$F(x)=P(X \leq x)=\sum_{{i|a_i \leq x}}p_i \quad (-\infty &lt; x &lt; +\infty)$$
称为 $X$ 的分布函数。实质上就是随机变量 $X$ 的部分可能取值的概率之和。分布函数有下面的一般性质：
 当 $x_1 &lt; x_2$ 时，有 $F(x_1) \leq F(x_2)$ 当 $x \to +\infty$ 时，$F(x) \to 1$；当 $x \to -\infty$ 时，$F(x) \to 0$  3、常见的离散型随机变量]]></description>
</item><item>
    <title>Winnower</title>
    <link>https://utopizza.github.io/2019-01-12-%E8%AE%BA%E6%96%87-winnower/</link>
    <pubDate>Sat, 12 Jan 2019 00:00:00 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://utopizza.github.io/2019-01-12-%E8%AE%BA%E6%96%87-winnower/</guid>
    <description><![CDATA[一、背景及问题
这篇文章针对的问题和前面看过的 《Dependence-Preserving Data Compaction for Scalable Forensic Analysis》和 这篇文章类似，目标都是减小日志文件的体积，以减少存储空间并提高攻击侦查的速度。
这篇文章主要针对的是分布式服务器集群下的 APT 攻击。在这样的情景中，服务器集群有一个中心监控节点（Monitor node），以及大量的工作节点（Worker nodes）。监控节点与所有的工作节点保持通信。工作节点在生产环境中不断地产生日志记录。当发起监控节点攻击侦查分析时，它需要从多个工作节点上拷贝日志文件到本地，再进行攻击分析。问题就出现在这里，大量的工作节点每天都产生大量的日志记录，监控节点几乎不可能从所有工作节点上拷贝全部的日志记录，因为这样的拷贝任务不但需要消耗大量的网络资源，并且需要消耗大量的存储空间。
二、解决方案
这篇文章和上述的那篇文章有点类似，其核心思想都是通过对资源图（Provenance Graph）进行剪枝、压缩、优化，从而减小对应的日志记录体积。不同的只是他们使用的剪枝算法不同而已，这篇文章使用的算法是一个称为 Deterministic Finite Automata (DFA) 的算法，这个算法可以对一个复杂的图中的每一个节点、边（对应系统日志记录中的事件以及信息流向）进行推断，判断出它是不是冗余的，如果是冗余的就可以去掉，从而极大提精简了日志记录。
文章提出的模型称为 Winnower，具体剪枝算法较复杂，主要分为图抽象（Provenance Graph Abstraction）和图推断（Provenance Graph Induction）两部分，其中涉及一些图语义学习（Graph Grammar Learning）的知识，以前没怎么接触过，感觉不太懂，以后有时间再补一下这方面的学习。]]></description>
</item><item>
    <title>线性变换的矩阵</title>
    <link>https://utopizza.github.io/2019-01-12-%E6%95%B0%E5%AD%A6-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E7%9A%84%E7%9F%A9%E9%98%B5/</link>
    <pubDate>Sat, 12 Jan 2019 00:00:00 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://utopizza.github.io/2019-01-12-%E6%95%B0%E5%AD%A6-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E7%9A%84%E7%9F%A9%E9%98%B5/</guid>
    <description><![CDATA[我们知道，线性空间中，在给定基的情况下，对任意一个向量 $\vec{v}$ 施予一个线性变换 $T$ 时，就让该向量的坐标向量左乘某个矩阵 $A$ 即可。例如，设在线性空间 $V_n(F)$ 中，取一组基为 ${\vec{\alpha_1},\vec{\alpha_2},\cdots,\vec{\alpha_n}}$，向量 $\vec{w}$ 在该基下的坐标为 $\vec{Y}$，向量 $\vec{v}$ 在该基下的坐标为 $\vec{X}$，即：
$$\vec{w}=(\vec{\alpha_1},\vec{\alpha_2},\cdots,\vec{\alpha_n}) \vec{Y}$$
$$\vec{v}=(\vec{\alpha_1},\vec{\alpha_2},\cdots,\vec{\alpha_n}) \vec{X}$$
如果向量 $\vec{w}$ 是由向量 $\vec{v}$ 经过线性变换 $T$ 得到的，即
$$\vec{w}=T(\vec{v})$$
那么它们的坐标关系为：
$$\vec{Y}=A \vec{X}$$
并且，线性空间中任一个线性变换 $T$ 可以由某个矩阵 $A$ 唯一对应：
$$T \iff A$$
为什么？这个矩阵 $A$ 如何得到？接下来复习一下 $A$ 的推导。需要的预备知识：
 线性空间定义 线性空间的基与坐标 线性变换定义   记 $T$ 为线性空间 $V_n(F)$ 上的线性变换。记 ${\vec{\alpha_1},\vec{\alpha_2},\cdots,\vec{\alpha_n}}$ 为 $V_n(F)$ 的一组基，则对任意向量 $\forall \pmb\beta \in V_n(F)$，由基的定义可得
 $$\vec{v}=(\vec{\alpha_1},\vec{\alpha_2},\cdots,\vec{\alpha_n}) \vec{X}=(\vec{\alpha_1},\vec{\alpha_2},\cdots,\vec{\alpha_n}) \begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix} =x_1\vec{\alpha_1}+x_2\vec{\alpha_2}+\cdots+x_n\vec{\alpha_n}$$  对 $\vec{v}$ 施予线性变换 $T$：]]></description>
</item></channel>
</rss>
