<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">

    <meta name="author" content="Yusheng Wang">
    <meta name="description" content="十二、运行Spark分布式程序
按照前面博客设置好Library后，选择Modules，可以看到导入的包列表如图（注意，这里包的顺序是会对项目的编译造成影响的，好像要把spark的包放在scala的包之前，否则编译的时候会报一些找不到某些函数的错误，具体问题忘了记录了，这个可以自己慢慢试试，百度上也有解决方案）
到这里，就可以运行单机/本地模式的spark程序了。要跑本地程序，命令如下（scala）：
val conf=new SparkConf().setAppName(“XXXX”).setMaster(“local”) 但是如果要运行集群模式的spark程序，必须还要将程序项目打包，并将这个程序分发到集群各个节点运行。要使程序分布式运行，命令如下：
val conf=new SparkConf().setAppName(“XXXX”).setMaster(“spark://master:8070”).setJars(List(“XXX”)) 其中的setMaster()里面的主机名和端口号需要根据你自己的实际配置进行设定，见第十节。而setJars()是本项目经过编译打包后的jar包的路径，要运行分布式程序必须添加这个包，否则会报错说workers找不到各种类
项目打包步骤如下：
(1) 进入 Artifacts-&gt;JAR-&gt;From modules with …
(2) 填入所建立的scala class的名字
(3) 选择Build on make，并记下项目打包输出的位置（重要！！）
设置完后，编译本项目。第一次编译的时候先不要在源码使用.setJars()这个函数。让编译通过。编译通过后，打开控制台，通过刚才的目录找到生成的Jar包。修改源码，加入这个包。在这里可以删除 “output root” 下的scala和spark的包，因为这两个包的导出没有什么意义。
(4) 根据路径找到与项目同名的JAR包：
(5) 运行Spark的分布式程序
(6) 正确运行结果
注意，如果程序运行一半，没有打印结果直接结束，有可能是内存不足导致程序直接死亡。这种情况下，可能不会报任何错误，在 WEB UI 上也只是显示 Finished 。我当时给master分配的内存从2G扩展到4G，才解决了这个问题，正确运行出结果。
参考：
 使用IDEA开发SPARK提交remote cluster执行 Windows下IntelliJ IDEA中调试Spark Standalone Spark入门实战系列&ndash;3.Spark编程模型（下）&ndash;IDEA搭建及实战  十三、使用Spark的机器学习库MLlib
我运行了其中的k-means算法，比较简单这里不再赘述，可参考：
  使用 Spark MLlib 做 K-means 聚类分析
  Scala Standard Library
  Spark学习1： 基础函数功能解读
  ">
    <meta name="keywords" content="blog,developer,personal">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Spark完全分布式搭建与使用(6)"/>
<meta name="twitter:description" content="十二、运行Spark分布式程序
按照前面博客设置好Library后，选择Modules，可以看到导入的包列表如图（注意，这里包的顺序是会对项目的编译造成影响的，好像要把spark的包放在scala的包之前，否则编译的时候会报一些找不到某些函数的错误，具体问题忘了记录了，这个可以自己慢慢试试，百度上也有解决方案）
到这里，就可以运行单机/本地模式的spark程序了。要跑本地程序，命令如下（scala）：
val conf=new SparkConf().setAppName(“XXXX”).setMaster(“local”) 但是如果要运行集群模式的spark程序，必须还要将程序项目打包，并将这个程序分发到集群各个节点运行。要使程序分布式运行，命令如下：
val conf=new SparkConf().setAppName(“XXXX”).setMaster(“spark://master:8070”).setJars(List(“XXX”)) 其中的setMaster()里面的主机名和端口号需要根据你自己的实际配置进行设定，见第十节。而setJars()是本项目经过编译打包后的jar包的路径，要运行分布式程序必须添加这个包，否则会报错说workers找不到各种类
项目打包步骤如下：
(1) 进入 Artifacts-&gt;JAR-&gt;From modules with …
(2) 填入所建立的scala class的名字
(3) 选择Build on make，并记下项目打包输出的位置（重要！！）
设置完后，编译本项目。第一次编译的时候先不要在源码使用.setJars()这个函数。让编译通过。编译通过后，打开控制台，通过刚才的目录找到生成的Jar包。修改源码，加入这个包。在这里可以删除 “output root” 下的scala和spark的包，因为这两个包的导出没有什么意义。
(4) 根据路径找到与项目同名的JAR包：
(5) 运行Spark的分布式程序
(6) 正确运行结果
注意，如果程序运行一半，没有打印结果直接结束，有可能是内存不足导致程序直接死亡。这种情况下，可能不会报任何错误，在 WEB UI 上也只是显示 Finished 。我当时给master分配的内存从2G扩展到4G，才解决了这个问题，正确运行出结果。
参考：
 使用IDEA开发SPARK提交remote cluster执行 Windows下IntelliJ IDEA中调试Spark Standalone Spark入门实战系列&ndash;3.Spark编程模型（下）&ndash;IDEA搭建及实战  十三、使用Spark的机器学习库MLlib
我运行了其中的k-means算法，比较简单这里不再赘述，可参考：
  使用 Spark MLlib 做 K-means 聚类分析
  Scala Standard Library
  Spark学习1： 基础函数功能解读
  "/>

    <meta property="og:title" content="Spark完全分布式搭建与使用(6)" />
<meta property="og:description" content="十二、运行Spark分布式程序
按照前面博客设置好Library后，选择Modules，可以看到导入的包列表如图（注意，这里包的顺序是会对项目的编译造成影响的，好像要把spark的包放在scala的包之前，否则编译的时候会报一些找不到某些函数的错误，具体问题忘了记录了，这个可以自己慢慢试试，百度上也有解决方案）
到这里，就可以运行单机/本地模式的spark程序了。要跑本地程序，命令如下（scala）：
val conf=new SparkConf().setAppName(“XXXX”).setMaster(“local”) 但是如果要运行集群模式的spark程序，必须还要将程序项目打包，并将这个程序分发到集群各个节点运行。要使程序分布式运行，命令如下：
val conf=new SparkConf().setAppName(“XXXX”).setMaster(“spark://master:8070”).setJars(List(“XXX”)) 其中的setMaster()里面的主机名和端口号需要根据你自己的实际配置进行设定，见第十节。而setJars()是本项目经过编译打包后的jar包的路径，要运行分布式程序必须添加这个包，否则会报错说workers找不到各种类
项目打包步骤如下：
(1) 进入 Artifacts-&gt;JAR-&gt;From modules with …
(2) 填入所建立的scala class的名字
(3) 选择Build on make，并记下项目打包输出的位置（重要！！）
设置完后，编译本项目。第一次编译的时候先不要在源码使用.setJars()这个函数。让编译通过。编译通过后，打开控制台，通过刚才的目录找到生成的Jar包。修改源码，加入这个包。在这里可以删除 “output root” 下的scala和spark的包，因为这两个包的导出没有什么意义。
(4) 根据路径找到与项目同名的JAR包：
(5) 运行Spark的分布式程序
(6) 正确运行结果
注意，如果程序运行一半，没有打印结果直接结束，有可能是内存不足导致程序直接死亡。这种情况下，可能不会报任何错误，在 WEB UI 上也只是显示 Finished 。我当时给master分配的内存从2G扩展到4G，才解决了这个问题，正确运行出结果。
参考：
 使用IDEA开发SPARK提交remote cluster执行 Windows下IntelliJ IDEA中调试Spark Standalone Spark入门实战系列&ndash;3.Spark编程模型（下）&ndash;IDEA搭建及实战  十三、使用Spark的机器学习库MLlib
我运行了其中的k-means算法，比较简单这里不再赘述，可参考：
  使用 Spark MLlib 做 K-means 聚类分析
  Scala Standard Library
  Spark学习1： 基础函数功能解读
  " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://utopizza.github.io/posts/spark/2016-07-05-spark-spark%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8-6/" />
<meta property="article:published_time" content="2016-07-05T22:44:00+00:00" />
<meta property="article:modified_time" content="2016-07-05T22:44:00+00:00" />


    
      <base href="https://utopizza.github.io/posts/spark/2016-07-05-spark-spark%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8-6/">
    
    <title>
  Spark完全分布式搭建与使用(6) · Utopizza
</title>

    
      <link rel="canonical" href="https://utopizza.github.io/posts/spark/2016-07-05-spark-spark%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8-6/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css" integrity="sha384-Bfad6CLCknfcloXFOyFnlgtENryhrpZCe29RTifKEixXQZ38WheV+i/6YWSzkz3V" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="https://utopizza.github.io/css/coder.min.a4f332213a21ce8eb521670c614470c58923aaaf385e2a73982c31dd7642decb.css" integrity="sha256-pPMyITohzo61IWcMYURwxYkjqq84XipzmCwx3XZC3ss=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="https://utopizza.github.io/css/coder-dark.min.e78e80fc3a585a4d1c8fc7f58623b6ff852411e38431a9cd1792877ecaa160f6.css" integrity="sha256-546A/DpYWk0cj8f1hiO2/4UkEeOEManNF5KHfsqhYPY=" crossorigin="anonymous" media="screen" />
      
    

    

    

    <link rel="icon" type="image/png" href="https://utopizza.github.io/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://utopizza.github.io/images/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.69.2" />
  </head>

  
  
    
  
  <body class="colorscheme-auto">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="https://utopizza.github.io/">
      Utopizza
    </a>
    
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://utopizza.github.io/about/">About</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://utopizza.github.io/posts/">Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://utopizza.github.io/projects/">Projects</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://utopizza.github.io/contact/">Contact me</a>
          </li>
        
      
      
    </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">Spark完全分布式搭建与使用(6)</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2016-07-05T22:44:00Z'>
                July 5, 2016
              </time>
            </span>
            <span class="reading-time">
              <i class="fas fa-clock"></i>
              1-minute read
            </span>
          </div>
          <div class="categories">
  <i class="fas fa-folder"></i>
    <a href="https://utopizza.github.io/categories/spark/">Spark</a></div>

          
        </div>
      </header>

      <div>
        
        <p>十二、运行Spark分布式程序</p>
<p>按照前面博客设置好Library后，选择Modules，可以看到导入的包列表如图（注意，这里包的顺序是会对项目的编译造成影响的，好像要把spark的包放在scala的包之前，否则编译的时候会报一些找不到某些函数的错误，具体问题忘了记录了，这个可以自己慢慢试试，百度上也有解决方案）</p>
<p><img src="https://utopizza.github.io/2016-07-05-Spark-Spark%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8-6/modules.jpg" alt=""></p>
<p>到这里，就可以运行单机/本地模式的spark程序了。要跑本地程序，命令如下（scala）：</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">val conf=new SparkConf().setAppName(“XXXX”).setMaster(“local”)
</code></pre></div><p>但是如果要运行集群模式的spark程序，必须还要将程序项目打包，并将这个程序分发到集群各个节点运行。要使程序分布式运行，命令如下：</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">val conf=new SparkConf().setAppName(“XXXX”).setMaster(“spark://master:8070”).setJars(List(“XXX”))
</code></pre></div><p>其中的setMaster()里面的主机名和端口号需要根据你自己的实际配置进行设定，见第十节。而setJars()是本项目经过编译打包后的jar包的路径，要运行分布式程序必须添加这个包，否则会报错说workers找不到各种类</p>
<p>项目打包步骤如下：</p>
<p>(1) 进入 Artifacts-&gt;JAR-&gt;From modules with …</p>
<p><img src="https://utopizza.github.io/2016-07-05-Spark-Spark%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8-6/package-1.jpg" alt=""></p>
<p>(2) 填入所建立的scala class的名字</p>
<p><img src="https://utopizza.github.io/2016-07-05-Spark-Spark%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8-6/package-2.jpg" alt=""></p>
<p>(3) 选择Build on make，并记下项目打包输出的位置（重要！！）</p>
<p><img src="https://utopizza.github.io/2016-07-05-Spark-Spark%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8-6/package-3.jpg" alt=""></p>
<p>设置完后，编译本项目。第一次编译的时候先不要在源码使用.setJars()这个函数。让编译通过。编译通过后，打开控制台，通过刚才的目录找到生成的Jar包。修改源码，加入这个包。在这里可以删除 “output root” 下的scala和spark的包，因为这两个包的导出没有什么意义。</p>
<p>(4) 根据路径找到与项目同名的JAR包：</p>
<p><img src="https://utopizza.github.io/2016-07-05-Spark-Spark%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8-6/package-4.jpg" alt=""></p>
<p>(5) 运行Spark的分布式程序</p>
<p><img src="https://utopizza.github.io/2016-07-05-Spark-Spark%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8-6/package-5.jpg" alt=""></p>
<p>(6) 正确运行结果</p>
<p><img src="https://utopizza.github.io/2016-07-05-Spark-Spark%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8-6/package-6.jpg" alt=""></p>
<p>注意，如果程序运行一半，没有打印结果直接结束，有可能是内存不足导致程序直接死亡。这种情况下，可能不会报任何错误，在 WEB UI 上也只是显示 Finished 。我当时给master分配的内存从2G扩展到4G，才解决了这个问题，正确运行出结果。</p>
<p>参考：</p>
<ul>
<li><a href="http://www.cnblogs.com/gaoxing/p/4414362.html">使用IDEA开发SPARK提交remote cluster执行</a></li>
<li><a href="http://blog.csdn.net/javastart/article/details/43372977">Windows下IntelliJ IDEA中调试Spark Standalone</a></li>
<li><a href="http://www.cnblogs.com/shishanyuan/p/4721120.html">Spark入门实战系列&ndash;3.Spark编程模型（下）&ndash;IDEA搭建及实战</a></li>
</ul>
<p>十三、使用Spark的机器学习库MLlib</p>
<p>我运行了其中的k-means算法，比较简单这里不再赘述，可参考：</p>
<ul>
<li>
<p><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-spark-practice4/">使用 Spark MLlib 做 K-means 聚类分析</a></p>
</li>
<li>
<p><a href="http://www.scala-lang.org/api/current/#scala.collection.immutable.StringLike">Scala Standard Library</a></p>
</li>
<li>
<p><a href="http://blog.csdn.net/yunlong34574/article/details/38635853">Spark学习1： 基础函数功能解读</a></p>
</li>
</ul>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

      </div>

      <script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

    </main>

    

    

    <script>
(function(f, a, t, h, o, m){
	a[h]=a[h]||function(){
		(a[h].q=a[h].q||[]).push(arguments)
	};
	o=f.createElement('script'),
	m=f.getElementsByTagName('script')[0];
	o.async=1; o.src=t; o.id='fathom-script';
	m.parentNode.insertBefore(o,m)
})(document, window, '//analytics.example.com/tracker.js', 'fathom');
fathom('set', 'siteId', 'ABCDE');
fathom('trackPageview');
</script>


  </body>

</html>
